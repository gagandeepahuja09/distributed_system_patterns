* Containerized applications managed by cloud-native platforms have no control over their lifecycle.
* To be good cloud-native citizens, they have to *listen to the events emitted by the managing platform* and adapt their lifecycles accordingly.

**Problem**
* Health-check APIs are ready-only endpoints the application is continually probing to get application insights.
* In addition to monitoring the state of a container, the platform may sometimes issue commands and expect the container to react on these. 
* It is up to the containerized application to determine which events are important to react to and how to react.

**Solution**
* Real-world applications require more fine-grained interactions and lifecycle management capabilities.
* Some applications need help to warm up, and some applications need a gentle and clean shutdown procedure.
* For this and other use cases, some events are emitted by the platform that the container can listen to and react to if desired.
* The events and hooks discussed here are all applied at an individual container level rather than pod level.

**SIGTERM Signal**
* Whenever Kubernetes decides to shut down a container, the container receives a SIGTERM signal. Could be due to: 
    * Pod it belongs to is shutting down(could be because of deployment).
    * A failed liveness probe causes the container to be restarted.
* SIGTERM is a gentle poke for the container to shut down cleanly before the container sends a more abrupt SIGKILL signal.
* Once a SIGTERM signal has been received, the application should shut down as quickly as possible.
* For some applications, this might be a quick termination, and some applications may have to *complete their in-flight requests*, *release open connections*, and *clean up temp files*, which can take a slightly longer time.

**SIGKILL Signal**
* If a process is not shut down after a SIGTERM signal, it is shut down forcefully by the following SIGKILL signal.
* Kubernetes waits for a grace period by default of 30 seconds after SIGTERM signal before sending the SIGKILL signal.
* The grace period can be defined per Pod using .spec.terminationGracePeriodSeconds

**PostStart Hook**
* Using only process signals for managing lifecycles is somewhat limited.
* Hence there are additional lifecycle hooks such as postStart and preStop provided by Kubernetes.
* The postStart command is executed after a container is executed, asynchronously with the primary container's process.

* The postStart action is a *blocking* call and the container status remains *Waiting* until the postStart handler completes, which in turn keeps the Pod status in the *Pending* state.

* Possible uses of postStart hook:
    1. The blocking nature of postStart can be used to delay the startup state of the container while giving the time to the main container to initialize.
    2. Preventing the container from starting when the Pod does not fulfill certain preconditions. Eg. when the postStart hook indicates an error by returning a non-zero error code, the main container process gets killed by Kubernetes.

* The postStart and preStop hook invocation mechanisms are similar to Health Probes and support these handler types:
    *exec*: Runs a command directly in the container.
    *httpGet*: Executes an HTTP GET request against a port opened by one Pod container.

* We have to be careful about what critical logic we execute in the postStart hook as there are no guarantess for its execution.
    * Since the hook is running in parallel with the container process, it's possible that the hook gets executed before the container has started.
    * The hook has atleast once semantics, hence the implementation should be able to take care of duplicate executions.
    * Note: It does not perform any retries for failed executions. 

* Example 5.1
    * sleep -> simulation of lengthy startup code.
    * We also use a trigger file here to sync with the main application which starts in parallel.